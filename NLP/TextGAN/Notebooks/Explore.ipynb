{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "vai Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from vaiutils import path_consts, randpick, smooth_plot\n",
    "from vainlp import extract_glove_embeddings\n",
    "from vaidata import pickle_dump, pickle_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Keras Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "PyTorch Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Define Useful Variables and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for k, v in path_consts(['GloVe', 'SampleText']):\n",
    "    exec(k+'=v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_text(vec):\n",
    "    return ' '.join(idx_word[i] for i in vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_DATA['GloVe'], 'glove.6B.50d.txt')) as f:\n",
    "    glove = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_DATA['SampleText'], 'styles.txt')) as f:\n",
    "    data = f.read().split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 2000\n",
    "embedding_dim = len(glove[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size)\n",
    "if os.path.exists(os.path.join(DIR_CHECKPOINTS, 'glove_embeddings.p')):\n",
    "    glove_embeddings = pickle_load(os.path.join(DIR_CHECKPOINTS, 'glove_embeddings.p'))\n",
    "    extract_glove_embeddings(data, glove, tokenizer, return_embeddings=False)\n",
    "else:\n",
    "    glove_embeddings = extract_glove_embeddings(data, glove, tokenizer)\n",
    "    pickle_dump(os.path.join(DIR_CHECKPOINTS, 'glove_embeddings.p'), glove_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_idx = tokenizer.word_index\n",
    "idx_word = {v: k for k, v in word_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = tokenizer.texts_to_sequences(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = [datum for datum in data if len(datum) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = [torch.from_numpy(np.array(datum, dtype=long)) for datum in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer.weight = nn.Parameter(torch.from_numpy(glove_embeddings.astype(float32)).cuda())\n",
    "embedding_weights = Variable(embedding_layer.weight.data.unsqueeze(1), volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.ConvTranspose1d(z_dim, embedding_dim*4, 3, 2, 1, 1)\n",
    "        self.conv2 = nn.ConvTranspose1d(embedding_dim*4, embedding_dim*2, 3, 2, 1, 1)\n",
    "        self.conv3 = nn.ConvTranspose1d(embedding_dim*2, embedding_dim, 3, 2, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x.unsqueeze(-1)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, embedding_dim*2, 3, 2, 1)\n",
    "        self.conv2 = nn.Conv1d(embedding_dim*2, embedding_dim*4, 3, 2, 1)\n",
    "        self.conv3 = nn.Conv1d(embedding_dim*4, 1, 3, 2, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.adaptive_avg_pool1d(x, 1).squeeze(0)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_g = optim.Adam(generator.parameters(), lr=1e-3)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'loss_g': [], 'loss_d': []}\n",
    "batches_per_epoch = len(data)\n",
    "\n",
    "def optimize(epochs=0, writes_per_epoch=10):\n",
    "    y_targets = [Variable(torch.from_numpy(np.array([i]).astype(float32)).cuda(), requires_grad=False) for i in range(2)]\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for batch in range(len(data)):\n",
    "            x = torch.unsqueeze(torch.transpose(embedding_layer(Variable(randpick(data).cuda(), requires_grad=False)), 0, 1), 0).cuda()\n",
    "            z = Variable(torch.randn(1, z_dim).cuda(), requires_grad=False)\n",
    "            \n",
    "            x_gen = generator(z)\n",
    "            \n",
    "            d_x = discriminator(x).squeeze()\n",
    "            d_x_gen = discriminator(x_gen).squeeze()\n",
    "            optimizer_g.zero_grad()\n",
    "            loss_g = criterion(d_x_gen, y_targets[1])\n",
    "            loss_g.backward(retain_graph=True)\n",
    "            optimizer_g.step()\n",
    "            \n",
    "            optimizer_d.zero_grad()\n",
    "            loss_d = criterion(d_x, y_targets[1]) + criterion(d_x_gen, y_targets[0])\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            if batch % int(batches_per_epoch / (writes_per_epoch - 1)) == 0:\n",
    "                history['loss_g'].append(loss_g.data.cpu().numpy()[0])\n",
    "                history['loss_d'].append(loss_d.data.cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:44<00:00, 44.84s/it]\n"
     ]
    }
   ],
   "source": [
    "optimize(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_plot(history, remove_outlier=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_text():\n",
    "    z = Variable(torch.randn(1, z_dim).cuda(), volatile=True)\n",
    "    x_gen = generator(z)\n",
    "    \n",
    "    vectors = torch.transpose(x_gen, 1, 2).repeat(vocab_size, 1, 1)\n",
    "    \n",
    "    distances = torch.norm(vectors - embedding_weights, dim=-1)\n",
    "    \n",
    "    probabilities = F.softmax(-torch.transpose(distances, 0, 1))\n",
    "    \n",
    "    return get_text(probabilities.max(1)[1].data.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'his hurriedly tangible withdrew his agitated tangible tangible.his agitated tangible withdrew case hurriedly tangible tangible.his hurriedly tangible withdrew case hurriedly tangible tangible.case tangible weak withdrew his agitated tangible tangible.his agitated tangible withdrew case hurriedly tangible tangible.his hurriedly tangible withdrew in hurriedly tangible tangible.his hurriedly tangible withdrew his hurriedly tangible tangible.his agitated tangible withdrew case hurriedly tangible tangible.case hurriedly weak withdrew his agitated tangible tangible.case hurriedly tangible withdrew his hurriedly tangible tangible'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'.'.join(sample_text() for _ in range(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
